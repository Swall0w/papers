# [FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks](https://arxiv.org/abs/1612.01925)
Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, Thomas Brox

University of Freiburg, Germany

## どんなもの？
FlowNetで提案されていたOptical FlowをCNNで行う手法を改善した。

## 先行研究と比べてどこがすごい？
FlowNetの改善手法はいくつか提案されていたが、革新的なものはなかった。
この提案する手法はFlowNetの推定エラーを50%近く減らし、ノイズを出さないようにし、精度と速さのトレードオフで8fps-140fps出るようになった。

## 技術や手法の肝はどこ？
コントリビューションとしては３つ
* 訓練時のデータの与え方の順番が精度に寄与することがわかった。(いきなり難しいThings3Dを与えるより、FlyingChairsを与えてからやるほうがいい)
* Networkをスタッキングさせていくほうがいいことがわかった(データの入力方法はちょっと特殊)
* ノイズのようなSmall DisplacementsにはFine-Tune

## どうやって有効だと検証したか？
FlowNet2.0の構造提案のときには、FlyingChaiersとSintelでablation studyで比較（Flying Chaierは訓練とテストデータがちかいため、過学習チェックができる)

## 議論はある？
8fpsから140fpsの幅と精度のトレードオフを説明しているが、定性的評価がないため、
使用時に140fpsが使えるのかがわからない

## 次に読むべき論文は？
* CNN based pathc matiching for optical flow with thresholed hinge loss
* Curriculum learning
* Human pose estimation with iterative error feedback
* A batch augmented loss for optical flow
* Stacked hourglass networks for human pose estimation
* Deepflow: Large displacement optical flow with deep matching
