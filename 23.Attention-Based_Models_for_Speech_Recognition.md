# [Attention-Based Models for Speech Recognition](https://arxiv.org/abs/1506.07503)
Jan Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, Yoshua Bengio

Universite de Montreal

## どんなもの？
Attentionメカニズムに基づく音声認識手法の提案

## 先行研究と比べてどこがすごい？
* 音声認識でのAttentionメカニズムの導入(結果として他の手法と検討できる精度達成)
* Attentionメカニズムにどこに着目するかの位置を示唆する汎用的な手法の提案
* Attentionメカニズムのときに、1フレームだけに固執しないような手法の導入

## 技術や手法の肝はどこ？
* 前のフレームまでの畳み込みにより、どこの位置に着目するかの特徴ベクトルの生成
* 入力が長くなったときに、とこに着目するかがが埋もれてしまうので、Sharpeningを導入（soft max関数を改良)
* しかし、上記のSharpeningでは短い文のときに影響されすぎてしまうので、Smoothingを導入(soft max関数を更に改良)

## どうやって有効だと検証したか？
* TIMITデータセットで検証
* 短い入力を繰り返させる、または結合させて長い入力を作り、学習時より長いものに対して認識できるかを実験

## 議論はある？
* 比較がBaseline, Conv Feats, Smooth Focusの3つだけだが、Sharpeningだけのときがないため、Smoothingが効いているのかがわからない

## 次に読むべき論文は？
* Neural machine translation by jointly learning to align and translate
* Recurrent models of visual attention
* Neural turing machines
* Memory networks
* Deepspeech: Scaling up end-to-end speech recogniton
* Long short-term memory
* Learning phrase representations using RNN encoder-decoder for statistical machine translation
* Labelling unsegmented sequence data with recurrent neural networks
* Sequence transduction with recurrent neural networks
* Towards end-to-end speech recognition with recurrent neural networks
