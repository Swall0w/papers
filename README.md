# thesis
## コース
- 1週目：　興味ある論文25本→　興味ある分野になぜ興味があるのかを考える
- 2週目：　テーマを絞って、25本→　先人がやり残していることは何かを考える
- 3週目：　先人がやり残していることを解決するためのアプローチを論文に限らず調べる。
- 4-7週目：　実装
- 8週目：　プレゼン

## 論文の研究と肩を並べるには？
- 試しに実装してみる
- 分からない場所は他の論文を見ながら調べる
- 自分の研究も同様だが、批判的な疑問点を持つ

## 読み方
- 1本の論文を時間に決めて読む
- 英語に詰まってもいいので、論理構造の把握に努める
* この論文は何をやったのか、何を証明したのか？
* 何を使って、それは今までのそれとはどう異なっているのか？
* 次は何を読めばいいんだろうか。

## まとめ方
* どんなもの？
* 先行研究と比べてどこがすごい？
* 技術や手法の肝はどこ？
* どうやって有効だと検証したか？
* 議論はある？
* 次に読むべき論文は？

```bash
## どんなもの？(コントリビューション)
## 先行研究と比べてどこがすごい？
## 技術や手法の肝はどこ？
## どうやって有効だと検証したか？
## 議論はある？
## 次に読むべき論文は？
```

## 自分の研究へ
* 批判的な態度を持つ
* 適切なベースラインを選定する
* 提案手法を構成要素に分解する
* 提案手法の構成要素を独立に評価する（ablation study）
* 同じ機能性を持った既存手法と比較する
* 提案手法のハイパーパラメータを評価する
* 既存（SoTA）手法と比較する

## 資料
* https://www.slideshare.net/mitmul/chainer-79942361
* http://qiita.com/icoxfog417/items/8689f943fd1225e24358
* http://qiita.com/aiskoaskosd/items/59c49f2e2a6d76d62798#%E5%86%85%E9%83%A8%E5%85%B1%E5%A4%89%E9%87%8F%E3%82%B7%E3%83%95%E3%83%88internal-covariate-shift

* http://studylog.hateblo.jp/entry/2016/12/05/125803
* [A Year in Computer Vision](http://www.themtank.org/a-year-in-computer-vision)
* [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/?utm_content=bufferf32c6&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)
