# [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
Ilya Sutskever, Oriol Vinyals, Quoc V. Le

Google

## どんなもの？(コントリビューション)
* 機械翻訳（English to French）でパラメータを調整しないでのモデルで今の既存の方法に勝った．
* ニューラルネットワークを用いて，可変長データから可変長データへのマッピングに成功

## 先行研究と比べてどこがすごい？
* ニューラルネットワークの機械翻訳の適用はあるものの，可変長データから可変長データへのマッピングは初めて
* 長い文章でも翻訳能力が落ちにくい(LSTMによる)

## 技術や手法の肝はどこ？
* 長期的に記憶が継続しにくいRNNではなくLSTMを用いた
* 浅いLSTMより深いLSTM（四段）を用いて，精度が上がった
* 入力を逆順し，LSTMへ入れた（ABC->123の文章なら，CBA->123といった感じに)

## どうやって有効だと検証したか？
WMT14 English to FrenchデータセットでのBlEU評価

## 議論はある？
* 文章の内容には特徴量が敏感に変わっているが，受動態，能動態での文章の違いには特徴量があまり変わらないのはなぜ？

## 次に読むべき論文は？
