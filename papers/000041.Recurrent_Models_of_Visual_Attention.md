# [Recurrent Models of Visual Attention](https://arxiv.org/abs/1406.6247)
Volodymyr Mnih Nicolas Heess Alex Graves Koray Kavukcuoglu

Google DeepMind
## どんなもの？(コントリビューション)
入力画像に対して，アテンションメカニズムを用いて着目する場所を絞らせることで物体認識を実現した点

## 先行研究と比べてどこがすごい？
* 強化学習の枠組みを用いた物体認識の提案
* 画像全体を処理するのではなく，幅を制限した受容部を動かすことで最終的に認識を行う．
* 画像全体を処理するわけではないため，画像の解像度が大きくなっても処理時間は依存しない

## 技術や手法の肝はどこ？
* 8x8などの幅を制限した受容（センサー）部分で画像を探索しながら最終的に推論するのが肝
* センサー部分を動かすことで画像の探索が出来，その方策の決定は周辺環境と過去の時系列データにより決定される．
* 微分不可なので，REINFORCEを適用

## どうやって有効だと検証したか？
* 28x28 MNIST
* 60x60 Translated MNIST
* 100x100 Cluttered Translated MNIST
のそれぞれのタスクで通常のMLP, ConvNet, RAMで比較．何回センサー部を移動するかによるが，MLP, ConvNetよりもエラーが少ないことが確認された．

また，ボールCatchゲームでの評価も行った．85%程度の精度

## 議論はある？
* 画像の解像度に対して，処理時間が独立ではあるが，通常のConvNetと比較した場合，フォワード演算ではどの程度時間がかかるのだろうか．

## 次に読むべき論文は？
