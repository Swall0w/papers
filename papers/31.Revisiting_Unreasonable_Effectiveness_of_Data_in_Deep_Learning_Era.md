# [Revisiting Unreasonable Effectiveness of Data in Deep Learning Era](https://arxiv.org/abs/1707.02968)
Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta

Google Research, Carnegie Mellon University

## どんなもの？
3億のデータセットでResNet101を学習し，データセットの量の違いで精度にどう影響を及ぼすかを検証した．

## 先行研究と比べてどこがすごい？
モデルの性能が上がってきているが，データセットはImageNetのままで，データセットの量の重要性と知見があまりなかった．

分散処理を用いてノイズラベルがあるが，JFT-300Mデータセットを学習し，
その結果比較より，データセット量が対数的に増えることでモデル精度が上がることを示した．

## 技術や手法の肝はどこ？
* 50台のK80でゴリゴリ処理

## どうやって有効だと検証したか？
* ImageNetへのFine Tuneによる精度比較
* Object Detection, Semantic Segmentation, Pose EstimationへのFine Tuneで，精度比較
* モデル容量(ResNet50, ResNet101, ResNet152)を変更しての学習での精度比較

## 議論はある？
* 今のデータセットに対して，モデルが収束してしまっている場合でも，データセット量が対数的増えることで精度が上がる可能性がある.
* 性能がいいモデルだからといって，ImageNetはそのモデルのパラメータを使用するには十分でないことがある．

## 次に読むべき論文は？
* Towards accurate multi-person pose estimation in the wild.
