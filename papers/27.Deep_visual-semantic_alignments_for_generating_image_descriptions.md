# [Deep visual-semantic alignments for generating image descriptions](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)
Andrej Karpathy Li Fei-Fei

Department of Computer Science, Stanford University

## どんなもの？
画像説明の文章生成手法の提案

## 先行研究と比べてどこがすごい？
物体検出ではカテゴリ数が限定されているが，これではデータセットのワードを弱教師として使うことで，
制限を取っ払うようにしているところ．

## 技術や手法の肝はどこ？
* 学習時に単語とその画像領域を同じ表現空間に埋め込むように学習しいること．
* 画像説明にはCNNとBidirectional RNN
* 一枚の画像に対し，RCNNを用いて，候補領域を算出し，その領域内のCNNでの表現とBidirectional RNNとを近づける．

## どうやって有効だと検証したか？
Flicker8K, Flicker30k, MSCOCO2014データセットを用いて，Blue, METEOR, CIDErで評価
提出時では画像説明ではSOTA(その後GoogleNICが出ており，その比較では負けている)

## 議論はある？
End-to-Endで学習が出来ないこと．

## 次に読むべき論文は？
