# [Multimodal Emoji Prediction](https://arxiv.org/abs/1803.02392)
Francesco Barbieri, Miguel Ballesteros, Francesco Ronzano, Horacio Saggion

IMIM-UPF, Barcelona, Spain,IBM Research, U.S

## どんなもの？(コントリビューション)
マルチモーダル（テキスト＋画像）によりどの絵文字が最適化を推定する手法を提案

## 先行研究と比べてどこがすごい？
先行研究ではTwitter情報を用いて，テキストから絵文字推定を行なっていたが，
本研究ではInstagramを用いて画像とテキストから絵文字を推定することでより精度の高い推定を行う点

## 技術や手法の肝はどこ？
- ResNetによる画像表現の埋め込み
- FastTextによるテキスト表現の埋め込み
- 二つの情報を統合し推定

## どうやって有効だと検証したか？
Instagramのデータを用いて，
- ベースライン（B-LSTM)との比較
- 推定結果の分析（やはり頻度が少ない絵文字が頻度の高いものに引っ張られている）
- Saliencyマップでの絵文字と画像のフォーカスがどこに対応しているかの可視化

## 議論はある？
片方情報が欠損した場合などの推定はどうなるのだろうか

## 次に読むべき論文は？
- [Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759)
