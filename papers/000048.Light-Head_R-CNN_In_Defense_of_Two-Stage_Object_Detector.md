# [Light-Head R-CNN: In Defense of Two-Stage Object Detector](https://arxiv.org/abs/1711.07264)
Zeming Li, Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, Jian Sun

Tsinghua University, Megvii Inc. (Face++)

## どんなもの？(コントリビューション)
* ２段階物体検出にて物体判定部分（Head)が重いことを指摘．
* 提案構造によりSoTA．
* 速度面においてはバックボーンを軽いものにすることで102FPS（30.７mAP@[.5:.95]）を出している．

## 先行研究と比べてどこがすごい？
* Faster R-CNN及びR−FCNのそれぞれの構造における問題点を指摘．
* Faster R-CNNはRoIpooling後にGlobal Average Pooling を使用しており，分類においては精度に貢献しているが，ローカライゼーションでは性能を損ねている．
* ２段階のFC層が重い
* R-FCNではPositive-sensitive Poolingを行なっているが，精度的にはRoI-wiseの構造より劣る．
* R-FCNは速度面においては１度の特徴量変換で良いので早いが，その特徴量マップが大きいためにRoI pooling後に計算量がかかる．


## 技術や手法の肝はどこ？
全体として薄くした構造

* 2つの手法から良いところをちょうどとった感じにした構造を提案．
* バックボーンからRPNで抜く特徴量マップは元のマップではなくR-FCNのように別のマップから抜く．
* ただし，抜く特徴量空間はクラス単位ではなく，大幅にチャネル数を減らした特徴量空間（バックボーン2048チャネルからCOCOでは490チャネル）
* 抜く時には通常のRoI PoolingまたはConvによるRSPoIでチャネルを減らして抜く．
* FC層は1つのみ．


## どうやって有効だと検証したか？
* RoI warpingの比較
* 評価自体はCOCOデータセット

## 議論はある？
* モデル全体としてのパラメータ数はどうなのだろうか．
* どこにどれだけ時間がかかっていたのかがわかると嬉しい．
* 性能評価によるとそもそもの性能自体はRetinaNetと同等．マルチスケールトレーニングが訓練面として物体検出の性能に影響している．

## 次に読むべき論文は？
* Deformable convolutional networks
* Identity mappings in deep residual networks
* Large kernel matters-improve semantic segmentation by global convolutional network
* object detection networks on convolutional feature maps.
* Denet: Scalable realtime object detection with directed sparse sampling.
* Shufflenet: An extremely efficient convolutional neural networks for mobile devices.
* Edge boxes: Locating object proposals from edges.
