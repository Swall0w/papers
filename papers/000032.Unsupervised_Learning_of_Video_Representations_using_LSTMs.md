# [Unsupervised Learning of Video Representations using LSTMs](https://arxiv.org/abs/1502.04681)
Srivastava, Nitish, Mansimov, Elman, Salakhutdinov, Ruslan

University of Toronto

## どんなもの？(コントリビューション)
* LSTMを用いて動画より時間的空間的な特徴量を教師なし学習で抽出した。
* 数フレームを入力、出力として復元（Auto Encoder)と予測を行うことで特徴量を抽出
* 教師あり学習へのFine-Tuneで精度が良くなることを示した。

## 先行研究と比べてどこがすごい？
* 動画から特徴量を抽出する方法はあったが、復元と予測を同時に行うことでよりいい特徴量を抽出する試みはなかった。

## 技術や手法の肝はどこ？
* 数フレーム入力後に入力と逆順番での復元するデコーダーと未来のフレームを予測するデコーダーを組み合わせていることで、エンコーダの性能を上げた。

## どうやって有効だと検証したか？
* moving MNISTを用い、復元、予測できているかを評価
* Sports-1Mで教師なし学習したもので、UCF-101/HMDB-51でアクション認識へのFine-Tune

## 議論はある？
* エンコーダが固定長になっているため、かなり特徴量が欠損してしまうのではないか？
* デコーダーが決定的なので、実際の予測の可視化ではすぐにぼやけてしまっている。確率的にする必要がある。

## 次に読むべき論文は？
* Sequence to Sequence Learning with Neural Networks
